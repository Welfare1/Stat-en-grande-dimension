---
title: "Question 4 : R√©gression sur Composantes Principales (PCR) - Analyse comparative des approches pour variables cat√©gorielles"
author: "Amed BAH"
date: today
lang: fr

format:
  pdf:
    documentclass: article
    geometry: margin=2.5cm
    fontsize: 11pt
    toc: true
    toc-depth: 3
    number-sections: true
    colorlinks: true
    fig-pos: 'H'
    fig-cap-location: bottom
    keep-tex: false
    include-in-header:
      text: |
        \usepackage{float}
        \usepackage{booktabs}
        \usepackage{longtable}
        \usepackage{array}
        \usepackage{multirow}
        \usepackage{wrapfig}
        \usepackage{colortbl}
        \usepackage{pdflscape}
        \usepackage{tabu}
        \usepackage{threeparttable}
        \usepackage{threeparttablex}
        \usepackage{makecell}
        \usepackage{xcolor}
  html:
    theme: cosmo
    toc: true
    toc-float: true
    code-fold: false
    number-sections: true
    fig-cap-location: bottom

editor: visual

execute:
  warning: false
  message: false
  echo: true
  fig-width: 8
  fig-height: 6
  fig-dpi: 300
---

## Question 4 : R√©gression sur composantes principales (PCR) {#sec-introduction}

Avant d'impl√©menter la PCR standard et de la comparer au Lasso, **nous avons identifi√© une probl√©matique m√©thodologique importante** : notre variable √† expliquer Y est cat√©gorielle (ALL vs AML), ce qui soul√®ve la question de savoir **si transformer cette variable en num√©rique pourrait poser des probl√®mes statistiques**.

### Objectif de cette analyse pr√©liminaire

En tant qu'√©tudiants en data science, nous souhaitons **prendre une d√©cision √©clair√©e** sur l'approche PCR √† adopter avant de r√©pondre √† la question principale. Cette analyse comparative nous permettra de :

1. **√âvaluer la validit√©** de transformer une variable cat√©gorielle en num√©rique pour la PCR
2. **Comparer les performances** de diff√©rentes approches PCR adapt√©es √† notre contexte
3. **Choisir la meilleure m√©thode** pour r√©pondre ensuite √† la question 4 du projet
4. **Pr√©parer la comparaison avec le Lasso** avec une approche PCR m√©thodologiquement solide

### Structure des donn√©es et d√©fi

- **Variables explicatives X** : num√©riques (p=1000 variables)
- **Variable √† expliquer Y** : cat√©gorielle binaire (ALL vs AML)  
- **D√©fi** : p >> n (1000 variables pour 72 observations)

### Approches PCR √©tudi√©es

Nous comparons deux strat√©gies principales :

**Approche 1 - PCR avec s√©lection optimis√©e :** 
- ACP sur les variables explicatives num√©riques
- S√©lection du nombre de composantes par validation crois√©e
- R√©gression logistique sur les composantes (respect de la nature cat√©gorielle de Y)

**Approche 2 - PCR classique :** 
- ACP sur les variables explicatives standardis√©es
- S√©lection bas√©e sur un crit√®re de variance expliqu√©e (85%)
- R√©gression logistique sur les composantes retenues

Cette analyse nous permettra ensuite de **r√©pondre rigoureusement √† la question 4** en utilisant l'approche PCR la plus appropri√©e.

## 1. Chargement des librairies et pr√©paration des donn√©es

```{r setup, message=FALSE, warning=FALSE}
# Charger les packages de base disponibles dans R
library(stats)     # Pour prcomp, glm
library(MASS)      # Pour LDA (optionnel)
library(knitr)     # Pour kable

# Packages pour am√©liorer l'affichage des tableaux
# Note: Si kableExtra n'est pas install√©, ex√©cutez: install.packages("kableExtra")
if (!require(kableExtra, quietly = TRUE)) {
  warning("Le package 'kableExtra' n'est pas install√©. Les tableaux seront affich√©s avec kable() basique.\nPour une meilleure pr√©sentation, installez le package avec: install.packages('kableExtra')")
  use_kableExtra <- FALSE
} else {
  library(kableExtra)
  use_kableExtra <- TRUE
}

set.seed(12311)

# Fonction utilitaire pour l'affichage des tableaux
format_table <- function(df, caption = NULL, col_names = NULL) {
  # Construire les arguments pour kable
  kable_args <- list(x = df, caption = caption, digits = 4)
  if (!is.null(col_names)) {
    kable_args$col.names <- col_names
  }
  
  if (use_kableExtra) {
    table <- do.call(kable, kable_args) %>%
      kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                    full_width = FALSE,
                    position = "center") %>%
      row_spec(0, bold = TRUE, color = "white", background = "#2c3e50")
    return(table)
  } else {
    return(do.call(kable, kable_args))
  }
}
```

### G√©n√©ration d'un jeu de donn√©es de haute dimension

```{r data_generation}
# Param√®tres du jeu de donn√©es (conforme au rapport principal)
n <- 72      # Nombre d'observations
p <- 1000    # Nombre de variables explicatives num√©riques

# G√©n√©ration des variables explicatives (toutes num√©riques)
set.seed(12311)
X <- matrix(rnorm(n * p), n, p)
colnames(X) <- paste0("V", 1:p)

# Variable √† expliquer (cat√©gorielle binaire)
y <- factor(sample(c("ALL", "AML"), n, replace = TRUE))

# Conversion en dataframe pour faciliter les manipulations
df_numeric <- data.frame(X, Y = y)

# R√©sum√© des caract√©ristiques du jeu de donn√©es
data_summary <- data.frame(
  Caracteristique = c("Dimensions", "Variables explicatives", "Observations", "Rapport p/n", "Type de Y"),
  Valeur = c(paste0(dim(df_numeric)[1], " √ó ", dim(df_numeric)[2]), 
             paste0(p, " (num√©riques)"),
             n,
             round(p/n, 2),
             "Cat√©gorielle binaire")
)

format_table(data_summary, 
             caption = "**Tableau 1**: Structure du jeu de donn√©es simul√©",
             col_names = c("Caract√©ristique", "Valeur"))

cat("\n")
format_table(as.data.frame(table(df_numeric$Y)), 
             caption = "**Tableau 2**: R√©partition de la variable cible Y",
             col_names = c("Classe", "Effectif"))
```

## 2. Impl√©mentation des approches PCR

### 2.1 Approche 1 : PCR avec optimisation par validation crois√©e

Nous commen√ßons par tester une approche o√π le nombre de composantes principales est s√©lectionn√© de mani√®re **data-driven** via validation crois√©e.

```{r pcr_approach1}

# S√©paration des donn√©es d'entra√Ænement et de test
set.seed(12311)
train_indices <- sample(1:n, size = floor(0.7 * n))
X_train <- X[train_indices, ]
X_test <- X[-train_indices, ]
y_train <- y[train_indices]
y_test <- y[-train_indices]

cat("Taille √©chantillon - Train:", length(y_train), "| Test:", length(y_test), "\n")

# PCA sur les donn√©es d'entra√Ænement
X_train_scaled <- scale(X_train)
X_test_scaled <- scale(X_test, center = attr(X_train_scaled, "scaled:center"), 
                                scale = attr(X_train_scaled, "scaled:scale"))

pca_result <- prcomp(X_train_scaled, center = FALSE, scale. = FALSE)

# Variance expliqu√©e
variance_explained <- (pca_result$sdev^2) / sum(pca_result$sdev^2) * 100
cumvar_explained <- cumsum(variance_explained)

cat("Variance expliqu√©e par les 10 premi√®res composantes:\n")
print(round(variance_explained[1:10], 2))

# Visualisation du scree plot
plot(1:min(20, length(variance_explained)), variance_explained[1:min(20, length(variance_explained))], 
     type = "b", col = "blue", pch = 19,
     main = "Scree Plot - Variance expliqu√©e par composante", 
     xlab = "Composante", ylab = "% Variance expliqu√©e")
abline(h = mean(variance_explained), col = "red", lty = 2, lwd = 2)
legend("topright", legend = "Moyenne", col = "red", lty = 2)
```



### S√©lection optimale du nombre de composantes par validation crois√©e

```{r optimal_components}
# Fonction pour √©valuer les performances avec un nombre donn√© de composantes
evaluate_pcr <- function(n_comp, X_scaled, y_data, cv_folds = 5) {
  set.seed(12311)
  n_obs <- nrow(X_scaled)
  
  # Cr√©ation des folds pour validation crois√©e
  fold_size <- floor(n_obs / cv_folds)
  indices <- sample(1:n_obs)
  
  accuracies <- numeric(cv_folds)
  
  for(i in 1:cv_folds) {
    # Indices du fold de test
    start_idx <- (i-1) * fold_size + 1
    end_idx <- ifelse(i == cv_folds, n_obs, i * fold_size)
    test_idx <- indices[start_idx:end_idx]
    
    # Division train/test
    X_train_cv <- X_scaled[-test_idx, ]
    X_test_cv <- X_scaled[test_idx, ]
    y_train_cv <- y_data[-test_idx]
    y_test_cv <- y_data[test_idx]
    
    # PCA sur train seulement
    pca_cv <- prcomp(X_train_cv, center = FALSE, scale. = FALSE)
    
    # Projeter sur les composantes
    train_components <- pca_cv$x[, 1:n_comp]
    test_components <- X_test_cv %*% pca_cv$rotation[, 1:n_comp]
    
    # Mod√®le logistique
    train_data_cv <- data.frame(train_components, Y = y_train_cv)
    test_data_cv <- data.frame(test_components, Y = y_test_cv)
    colnames(test_data_cv)[1:n_comp] <- colnames(train_data_cv)[1:n_comp]
    
    model_cv <- glm(Y ~ ., data = train_data_cv, family = binomial())
    pred_prob_cv <- predict(model_cv, test_data_cv, type = "response")
    pred_class_cv <- ifelse(pred_prob_cv > 0.5, "AML", "ALL")
    
    accuracies[i] <- mean(pred_class_cv == as.character(y_test_cv))
  }
  
  return(mean(accuracies))
}

# Tester diff√©rents nombres de composantes
n_comp_range <- c(2, 3, 4, 5, 6, 8, 10, 12, 15, 20, 25, 30)
n_comp_range <- n_comp_range[n_comp_range < n]  # Limiter √† n-1

cv_results <- sapply(n_comp_range, function(nc) evaluate_pcr(nc, X_train_scaled, y_train))

# Trouver le nombre optimal de composantes
optimal_ncomp <- n_comp_range[which.max(cv_results)]

# Affichage des r√©sultats de validation crois√©e
cv_results_table <- data.frame(
  Composantes = n_comp_range,
  Accuracy_CV = round(cv_results, 3)
)

# Affichage des r√©sultats avec mise en forme
if (use_kableExtra) {
  kable(cv_results_table, 
        caption = "**Tableau 3**: R√©sultats de validation crois√©e pour diff√©rents nombres de composantes",
        col.names = c("Nombre de composantes", "Accuracy CV"),
        digits = 4) %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed")) %>%
    row_spec(which.max(cv_results), bold = TRUE, color = "white", background = "#28a745")
} else {
  format_table(cv_results_table, 
               caption = "**Tableau 3**: R√©sultats de validation crois√©e pour diff√©rents nombres de composantes",
               col_names = c("Nombre de composantes", "Accuracy CV"))
}

optimal_result <- data.frame(
  Optimal_Components = optimal_ncomp,
  Best_CV_Accuracy = round(max(cv_results), 3)
)

format_table(optimal_result, 
             caption = "**Tableau 4**: R√©sultat optimal de la validation crois√©e",
             col_names = c("Composantes optimales", "Meilleure Accuracy CV"))

# Visualisation des r√©sultats CV
plot(n_comp_range, cv_results, type = "b", col = "darkgreen", pch = 19,
     main = "Validation crois√©e: Performance vs nombre de composantes",
     xlab = "Nombre de composantes", ylab = "Accuracy CV")
abline(v = optimal_ncomp, col = "red", lty = 2, lwd = 2)
legend("bottomright", legend = paste("Optimal:", optimal_ncomp), col = "red", lty = 2)
```

### Classification finale avec le nombre optimal de composantes

```{r pcr_final_classification}
# PCA avec le nombre optimal de composantes
pc_train <- pca_result$x[, 1:optimal_ncomp]
pc_test <- X_test_scaled %*% pca_result$rotation[, 1:optimal_ncomp]

# Cr√©ation des datasets
train_data <- data.frame(pc_train, Y = y_train)
test_data <- data.frame(pc_test, Y = y_test)
colnames(test_data)[1:optimal_ncomp] <- colnames(train_data)[1:optimal_ncomp]

# Mod√®le final
final_model <- glm(Y ~ ., data = train_data, family = binomial())

# Pr√©dictions sur le test set
pred_prob <- predict(final_model, test_data, type = "response")
pred_class <- ifelse(pred_prob > 0.5, "AML", "ALL")
pred_class <- factor(pred_class, levels = levels(y_test))

# M√©triques de performance
confusion_matrix <- table(Predicted = pred_class, Actual = y_test)
accuracy_pcr1 <- sum(diag(confusion_matrix)) / sum(confusion_matrix)

# R√©sultats PCR Standard (Approche 1)
results_pcr1 <- data.frame(
  Metrique = c("Composantes utilis√©es", "Accuracy test"),
  Valeur = c(optimal_ncomp, round(accuracy_pcr1, 3))
)

format_table(results_pcr1, 
             caption = "**Tableau 5**: R√©sultats PCR Standard (Approche 1 - Validation crois√©e)",
             col_names = c("M√©trique", "Valeur"))

# Matrice de confusion avec formatage appropri√©
if (use_kableExtra) {
  kable(confusion_matrix, 
        caption = "**Tableau 6**: Matrice de confusion - PCR Standard (Approche 1)",
        digits = 0) %>%
    kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE) %>%
    add_header_above(c(" " = 1, "Valeurs r√©elles" = 2))
} else {
  format_table(confusion_matrix, 
               caption = "**Tableau 6**: Matrice de confusion - PCR Standard (Approche 1)")
}
```

## Approche 2: PCR Classique avec nombre fixe de composantes

### Impl√©mentation de la PCR classique

```{r classical_pcr}
# PCR classique avec nombre de composantes bas√© sur la variance cumul√©e
# Crit√®re: 85% de variance expliqu√©e

# Trouver le nombre de composantes pour 85% de variance
ncomp_classical <- which(cumvar_explained >= 85)[1]
if (is.na(ncomp_classical)) ncomp_classical <- min(20, length(variance_explained))

# Extraction des composantes pour train et test
pc_train_classical <- pca_result$x[, 1:ncomp_classical]
pc_test_classical <- X_test_scaled %*% pca_result$rotation[, 1:ncomp_classical]

# Cr√©ation des datasets
train_data_classical <- data.frame(pc_train_classical, Y = y_train)
test_data_classical <- data.frame(pc_test_classical, Y = y_test)
colnames(test_data_classical)[1:ncomp_classical] <- colnames(train_data_classical)[1:ncomp_classical]

# Mod√®le logistique
model_classical <- glm(Y ~ ., data = train_data_classical, family = binomial())

# Pr√©dictions
pred_prob_classical <- predict(model_classical, test_data_classical, type = "response")
pred_class_classical <- ifelse(pred_prob_classical > 0.5, "AML", "ALL")
pred_class_classical <- factor(pred_class_classical, levels = levels(y_test))

# M√©triques de performance
confusion_matrix_classical <- table(Predicted = pred_class_classical, Actual = y_test)
accuracy_pcr2 <- sum(diag(confusion_matrix_classical)) / sum(confusion_matrix_classical)

# R√©sultats PCR Classique (Approche 2)
pcr_classical_info <- data.frame(
  Critere = "85% de variance cumul√©e expliqu√©e",
  Composantes_selectionnees = ncomp_classical,
  Variance_expliquee = paste0(round(cumvar_explained[ncomp_classical], 2), "%"),
  Accuracy_test = round(accuracy_pcr2, 3)
)

format_table(as.data.frame(t(pcr_classical_info)), 
             caption = "**R√©sultats PCR Classique (Approche 2)**",
             col_names = c("Valeur"))

cat("\n**Matrice de confusion PCR Classique:**\n")
format_table(confusion_matrix_classical, 
             caption = "Matrice de confusion - PCR Classique (Approche 2)")
```

## 3. Premiers r√©sultats et questionnement m√©thodologique

### 3.1 Synth√®se des r√©sultats obtenus

```{r comparison_plots}
# Comparaison visuelle des deux approches
comparison_data <- data.frame(
  Approche = c("PCR Optimis√©e (CV)", "PCR Classique (85% var)"),
  Accuracy = c(accuracy_pcr1, accuracy_pcr2),
  N_Components = c(optimal_ncomp, ncomp_classical),
  Criterion = c("Validation crois√©e", "85% variance")
)

# Comparaison avec formatage appropri√©
if (use_kableExtra) {
  kable(comparison_data, 
        caption = "**Tableau 7**: Comparaison initiale des approches PCR",
        col.names = c("Approche", "Accuracy", "Nb Composantes", "Crit√®re"),
        digits = 4) %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed")) %>%
    row_spec(which.max(comparison_data$Accuracy), bold = TRUE, color = "white", background = "#17a2b8")
} else {
  format_table(comparison_data, 
               caption = "**Tableau 7**: Comparaison initiale des approches PCR",
               col_names = c("Approche", "Accuracy", "Nb Composantes", "Crit√®re"))
}

# Graphique de comparaison
par(mfrow = c(1, 2))

# Comparaison des accuracies
barplot(comparison_data$Accuracy, 
        names.arg = c("PCR Optimis√©e", "PCR Classique"),
        main = "Performances initiales",
        ylab = "Accuracy",
        col = c("darkgreen", "darkred"),
        ylim = c(0, 1))
text(1:2, comparison_data$Accuracy + 0.05, 
     labels = round(comparison_data$Accuracy, 3), 
     pos = 3)

# Comparaison du nombre de composantes
barplot(comparison_data$N_Components,
        names.arg = c("PCR Optimis√©e", "PCR Classique"),
        main = "Nombre de composantes utilis√©es",
        ylab = "Nombre de composantes",
        col = c("darkgreen", "darkred"))
text(1:2, comparison_data$N_Components + 1,
     labels = comparison_data$N_Components,
     pos = 3)

par(mfrow = c(1, 1))
```

### Discussion et conclusions

::: {.callout-note}
## üìä R√©sum√© des r√©sultats principaux

**Approche 1 - PCR avec optimisation par validation crois√©e :**
- Nombre optimal de composantes : `r optimal_ncomp`
- Accuracy sur donn√©es de test : `r round(accuracy_pcr1, 3)`
- Avantage : S√©lection data-driven du nombre de composantes

**Approche 2 - PCR classique (85% de variance) :**
- Nombre de composantes : `r ncomp_classical`
- Accuracy sur donn√©es de test : `r round(accuracy_pcr2, 3)`
- Avantage : Crit√®re simple et interpr√©table
:::

#### Analyse des r√©sultats

#### Contexte de haute dimension

Ce jeu de donn√©es simul√© (n=72, p=1000) repr√©sente un d√©fi typique de la statistique en grande dimension o√π p >> n. Dans ce contexte :

1. **R√©duction drastique** : Les deux approches r√©duisent efficacement de 1000 variables √† quelques composantes principales
2. **Stabilit√© num√©rique** : PCR √©vite les probl√®mes d'instabilit√© num√©rique li√©s √† l'inversion de matrices singuli√®res
3. **Performance comparable** : Les deux approches donnent des r√©sultats similaires, validant la robustesse de l'approche PCR

#### Comparaison avec d'autres m√©thodes

Par rapport au Lasso sur donn√©es de haute dimension :
- **PCR** : Toujours applicable m√™me quand p >> n
- **Lasso** : Peut √©chouer avec des p√©nalisations trop fortes
- **Interpr√©tabilit√©** : PCR privil√©gie la pr√©diction, Lasso privil√©gie la s√©lection

#### Recommandations pratiques

1. **Pour la performance** : Utiliser la validation crois√©e pour optimiser le nombre de composantes
2. **Pour la simplicit√©** : Le crit√®re de variance cumul√©e reste une alternative viable
3. **Pour la robustesse** : PCR est particuli√®rement adapt√©e aux contextes de haute dimension
4. **Pour l'interpr√©tation** : Analyser la contribution des variables originales aux composantes principales retenues

### 3.2 Question m√©thodologique soulev√©e

**Observation importante :** Nos deux approches utilisent toutes les deux une r√©gression logistique (m√©thode adapt√©e √† la classification). Cependant, nous nous demandons si certaines impl√©mentations de PCR dans la litt√©rature pourraient **transformer la variable cat√©gorique en num√©rique** avant d'appliquer une r√©gression lin√©aire classique.

**Question de recherche :** Cette transformation serait-elle valide statistiquement ? Quels seraient les impacts sur la performance et l'interpr√©tabilit√© ?

En tant qu'√©tudiants consciencieux, nous souhaitons **explorer cette question** avant de finaliser notre choix d'approche pour la Question 4.

## 4. Investigation : PCR avec transformation num√©rique vs PCR adapt√©e

### 4.1 Probl√©matique identifi√©e

Dans certaines applications de PCR que nous avons pu observer, la variable cat√©gorielle est parfois transform√©e en variable num√©rique. Nous souhaitons **tester empiriquement** les cons√©quences de cette approche pour **valider ou invalider** cette pratique.

### 4.2 Comparaison des deux philosophies

**Approche A - PCR "classique" avec transformation :** 
1. Transformer Y cat√©gorielle ‚Üí Y num√©rique (ALL=0, AML=1)
2. Appliquer une r√©gression lin√©aire sur les composantes principales
3. Classifier par seuillage (> 0.5 = AML)

**Approche B - PCR adapt√©e √† la classification :** 
1. Conserver Y cat√©gorielle
2. Appliquer une r√©gression logistique sur les composantes principales  
3. Classifier par probabilit√© maximale

### 4.3 M√©thodologie de comparaison

Nous testons les deux approches sur le **m√™me jeu de donn√©es** et les **m√™mes composantes principales** pour assurer une comparaison √©quitable.

**√âtape 3 - Mod√©lisation :**
- R√©gression logistique : P(Y="AML") = logit‚Åª¬π(Œ≤‚ÇÄ + Œ≤‚ÇÅ√óPC1 + ... + Œ≤‚Çñ√óPCk)

**√âtape 4 - Pr√©diction :**
- Pr√©diction probabiliste : PÃÇ(Y="AML")
- Classification : ≈∑_classe = "AML" si PÃÇ(Y="AML") > 0.5, sinon "ALL"

**√âtape 5 - √âvaluation :**
- Accuracy, matrice de confusion, probabilit√©s de classe

### Impl√©mentation comparative sur le jeu de donn√©es

```{r pcr_numeric_vs_categorical}
print("Comparaison PCR Classique vs PCR Adapt√©e")

# Utilisation des m√™mes composantes principales (85% variance) pour comparaison √©quitable
components_data <- data.frame(pc_train_classical, y_train_num = ifelse(y_train == "AML", 1, 0), y_train_cat = y_train)
test_components_data <- data.frame(pc_test_classical, y_test_num = ifelse(y_test == "AML", 1, 0), y_test_cat = y_test)

# Approche 1: PCR Classique (cible num√©rique)
print("Approche 1: PCR Classique (cible num√©rique)")

# Mod√®le de r√©gression lin√©aire
model_pcr_numeric <- lm(y_train_num ~ ., data = components_data[, c(colnames(pc_train_classical), "y_train_num")])

# Pr√©dictions continues
pred_continuous <- predict(model_pcr_numeric, test_components_data)

# R√©sum√© des pr√©dictions continues
pred_summary_numeric <- data.frame(
  Statistique = c("Exemple (6 premiers)", "Minimum", "Maximum"),
  Valeur = c(paste(round(head(pred_continuous), 3), collapse=", "), 
             round(min(pred_continuous), 3), 
             round(max(pred_continuous), 3))
)
print(pred_summary_numeric)

# Classification par seuillage
pred_class_numeric <- ifelse(pred_continuous > 0.5, "AML", "ALL")
pred_class_numeric <- factor(pred_class_numeric, levels = levels(y_test))

# M√©triques
accuracy_numeric <- mean(pred_class_numeric == y_test)
confusion_numeric <- table(Predicted = pred_class_numeric, Actual = y_test)

print(paste("Accuracy PCR classique:", round(accuracy_numeric, 3)))
print("Matrice de confusion PCR classique:")
print(confusion_numeric)

# Approche 2: PCR Adapt√©e (cible cat√©gorielle)
print("Approche 2: PCR Adapt√©e (cible cat√©gorielle)")

# Mod√®le de r√©gression logistique (d√©j√† calcul√© pr√©c√©demment)
model_pcr_categorical <- model_classical  # R√©utiliser le mod√®le d√©j√† cr√©√©

# Pr√©dictions probabilistes
pred_probabilities <- predict(model_pcr_categorical, test_data_classical, type = "response")

# R√©sum√© des probabilit√©s pr√©dites
pred_summary_categorical <- data.frame(
  Statistique = c("Exemple (6 premiers)", "Minimum", "Maximum"),
  Valeur = c(paste(round(head(pred_probabilities), 3), collapse=", "), 
             round(min(pred_probabilities), 3), 
             round(max(pred_probabilities), 3))
)
print(pred_summary_categorical)

# Classification
pred_class_categorical <- ifelse(pred_probabilities > 0.5, "AML", "ALL")
pred_class_categorical <- factor(pred_class_categorical, levels = levels(y_test))

# M√©triques (d√©j√† calcul√©es)
accuracy_categorical <- accuracy_pcr2
confusion_categorical <- confusion_matrix_classical

print(paste("Accuracy PCR adapt√©e:", round(accuracy_categorical, 3)))
print("Matrice de confusion PCR adapt√©e:")
print(confusion_categorical)

# ===== CALCUL DE M√âTRIQUES D√âTAILL√âES =====
calculate_detailed_metrics <- function(conf_matrix) {
  if(all(c("ALL", "AML") %in% rownames(conf_matrix)) && all(c("ALL", "AML") %in% colnames(conf_matrix))) {
    tp <- conf_matrix["AML", "AML"]  # Vrais positifs
    tn <- conf_matrix["ALL", "ALL"]  # Vrais n√©gatifs
    fp <- conf_matrix["AML", "ALL"]  # Faux positifs
    fn <- conf_matrix["ALL", "AML"]  # Faux n√©gatifs
    
    sensitivity <- tp / (tp + fn)  # Sensibilit√© (rappel pour AML)
    specificity <- tn / (tn + fp)  # Sp√©cificit√©
    precision <- tp / (tp + fp)    # Pr√©cision pour AML
    
    return(list(sensitivity = sensitivity, specificity = specificity, precision = precision))
  } else {
    return(list(sensitivity = NA, specificity = NA, precision = NA))
  }
}

metrics_numeric <- calculate_detailed_metrics(confusion_numeric)
metrics_categorical <- calculate_detailed_metrics(confusion_categorical)

# M√©triques d√©taill√©es comparatives
cat("**M√©triques d√©taill√©es - PCR Classique (num√©rique):**\n")
metrics_table_numeric <- data.frame(
  Metrique = c("Sensibilit√© (d√©tection AML)", "Sp√©cificit√© (d√©tection ALL)", "Pr√©cision (AML pr√©dits)"),
  Valeur = round(c(metrics_numeric$sensitivity, metrics_numeric$specificity, metrics_numeric$precision), 3)
)
format_table(metrics_table_numeric, 
             caption = "M√©triques d√©taill√©es - Approche num√©rique",
             col_names = c("M√©trique", "Valeur"))

cat("\n**M√©triques d√©taill√©es - PCR Adapt√©e (cat√©gorielle):**\n")
metrics_table_categorical <- data.frame(
  Metrique = c("Sensibilit√© (d√©tection AML)", "Sp√©cificit√© (d√©tection ALL)", "Pr√©cision (AML pr√©dits)"),
  Valeur = round(c(metrics_categorical$sensitivity, metrics_categorical$specificity, metrics_categorical$precision), 3)
)
format_table(metrics_table_categorical, 
             caption = "M√©triques d√©taill√©es - Approche cat√©gorielle",
             col_names = c("M√©trique", "Valeur"))
```

### Synth√®se comparative et visualisations

```{r comparative_summary}
# Tableau comparatif des r√©sultats
comparative_results <- data.frame(
  Approche = c("PCR Classique (num√©rique)", "PCR Adapt√©e (cat√©gorielle)"),
  Accuracy = c(accuracy_numeric, accuracy_categorical),
  Sensibilite = c(metrics_numeric$sensitivity, metrics_categorical$sensitivity),
  Specificite = c(metrics_numeric$specificity, metrics_categorical$specificity),
  Precision = c(metrics_numeric$precision, metrics_categorical$precision)
)

format_table(round(comparative_results[, -1], 3), 
             caption = "**Tableau 8**: Comparaison d√©taill√©e des approches PCR",
             col_names = c("Accuracy", "Sensibilit√©", "Sp√©cificit√©", "Pr√©cision"))

# Visualisations comparatives
par(mfrow = c(2, 2))

# 1. Comparaison des accuracies
barplot(comparative_results$Accuracy,
        names.arg = c("PCR\nClassique", "PCR\nAdapt√©e"),
        col = c("lightblue", "lightgreen"),
        ylim = c(0, 1),
        main = "Accuracy",
        ylab = "Accuracy")
text(1:2, comparative_results$Accuracy + 0.05,
     labels = round(comparative_results$Accuracy, 3),
     pos = 3)

# 2. Comparaison des sensibilit√©s
barplot(comparative_results$Sensibilite,
        names.arg = c("PCR\nClassique", "PCR\nAdapt√©e"),
        col = c("lightcoral", "lightblue"),
        ylim = c(0, 1),
        main = "Sensibilit√© (d√©tection AML)",
        ylab = "Sensibilit√©")
text(1:2, comparative_results$Sensibilite + 0.05,
     labels = round(comparative_results$Sensibilite, 3),
     pos = 3)

# 3. Comparaison des sp√©cificit√©s
barplot(comparative_results$Specificite,
        names.arg = c("PCR\nClassique", "PCR\nAdapt√©e"),
        col = c("lightyellow", "lightpink"),
        ylim = c(0, 1),
        main = "Sp√©cificit√© (d√©tection ALL)",
        ylab = "Sp√©cificit√©")
text(1:2, comparative_results$Specificite + 0.05,
     labels = round(comparative_results$Specificite, 3),
     pos = 3)

# 4. Comparaison des pr√©cisions
barplot(comparative_results$Precision,
        names.arg = c("PCR\nClassique", "PCR\nAdapt√©e"),
        col = c("lightsteelblue", "lightseagreen"),
        ylim = c(0, 1),
        main = "Pr√©cision (pr√©dictions AML)",
        ylab = "Pr√©cision")
text(1:2, comparative_results$Precision + 0.05,
     labels = round(comparative_results$Precision, 3),
     pos = 3)

par(mfrow = c(1, 1))

# Analyse des distributions des pr√©dictions
par(mfrow = c(1, 2))

# Distribution des pr√©dictions PCR classique
hist(pred_continuous, 
     main = "PCR Classique\nDistribution des pr√©dictions continues",
     xlab = "Valeur pr√©dite", 
     ylab = "Fr√©quence",
     col = "lightblue",
     breaks = 10)
abline(v = 0.5, col = "red", lwd = 2, lty = 2)

# Distribution des probabilit√©s PCR adapt√©e
hist(pred_probabilities, 
     main = "PCR Adapt√©e\nDistribution des probabilit√©s",
     xlab = "P(Y = AML)", 
     ylab = "Fr√©quence",
     col = "lightgreen",
     breaks = 10)
abline(v = 0.5, col = "red", lwd = 2, lty = 2)

par(mfrow = c(1, 1))
```

### Analyse critique des avantages et inconv√©nients

#### Validit√© statistique

**PCR Classique (cible num√©rique) :**
- ‚ùå **Violation des hypoth√®ses** : La r√©gression lin√©aire suppose une relation lin√©aire et une distribution normale des r√©sidus, inadapt√©es √† une variable binaire
- ‚ùå **Homosc√©dasticit√©** : La variance des r√©sidus n'est pas constante pour une variable binaire
- ‚ùå **Pr√©dictions aberrantes** : Possibilit√© de pr√©dire des valeurs < 0 ou > 1, sans interpr√©tation probabiliste
- ‚ùå **Seuillage arbitraire** : Le choix du seuil 0.5 peut √™tre sous-optimal

**PCR Adapt√©e (cible cat√©gorielle) :**
- ‚úÖ **Mod√®le appropri√©** : La r√©gression logistique est sp√©cifiquement con√ßue pour les variables cat√©gorielles
- ‚úÖ **Hypoth√®ses respect√©es** : Pas d'hypoth√®se de normalit√© des r√©sidus
- ‚úÖ **Interpr√©tation probabiliste** : Pr√©dictions entre 0 et 1 avec interpr√©tation naturelle
- ‚úÖ **Flexibilit√©** : Possibilit√© d'ajuster le seuil de d√©cision selon le contexte

#### Interpr√©tabilit√©

**PCR Classique :**
- ‚ùå **Pr√©dictions continues ambigu√´s** : Une pr√©diction de 0.3 ou 0.7 n'a pas de sens intuitif
- ‚ùå **Coefficients difficiles √† interpr√©ter** : Relation lin√©aire forc√©e inappropriate
- ‚ö†Ô∏è **Diagnostic du mod√®le complexe** : Les r√©sidus ne suivent pas les patterns attendus

**PCR Adapt√©e :**
- ‚úÖ **Probabilit√©s interpr√©tables** : P(Y="AML") = 0.7 signifie 70% de chance d'√™tre AML
- ‚úÖ **Coefficients logistiques** : Impact multiplicatif sur les odds, interpr√©tation standard
- ‚úÖ **Diagnostic appropri√©** : Courbes ROC, tests de Hosmer-Lemeshow disponibles

#### Performance pr√©dictive

**Observations sur notre jeu de donn√©es :**
- Accuracy PCR Classique : `r round(accuracy_numeric, 3)`
- Accuracy PCR Adapt√©e : `r round(accuracy_categorical, 3)`

**Analyse :**
- Les performances peuvent √™tre similaires sur certains jeux de donn√©es
- La PCR adapt√©e est g√©n√©ralement plus stable et robuste
- Moins de risque de sur-ajustement avec la r√©gression logistique

#### Pertinence m√©thodologique

**PCR Classique :**
- ‚ö†Ô∏è **Usage d√©conseill√©** pour variables cat√©gorielles en g√©n√©ral
- ‚ö†Ô∏è **Acceptable uniquement** comme approximation grossi√®re en exploration pr√©liminaire
- ‚ùå **Non recommand√©e** pour publication scientifique ou prise de d√©cision

**PCR Adapt√©e :**
- ‚úÖ **Standard m√©thodologique** pour classification avec r√©duction de dimension
- ‚úÖ **Accept√©e acad√©miquement** et professionnellement
- ‚úÖ **Extensible** √† la classification multiclasse (r√©gression logistique multinomiale)

#### Autres m√©thodes de r√©duction de dimension pour la classification

Bien que la PCR adapt√©e soit sup√©rieure √† la PCR classique, d'autres m√©thodes sp√©cialis√©es m√©ritent d'√™tre consid√©r√©es :

#### PLS-DA (Partial Least Squares - Discriminant Analysis)

**Principe :**
- M√©thode **supervis√©e** qui utilise l'information de la variable cible lors de la r√©duction de dimension
- Trouve des composantes qui maximisent √† la fois la variance des X et la covariance X-Y
- Particuli√®rement efficace en haute dimension

**Impl√©mentation conceptuelle :**
```{r pls_da_concept, eval=FALSE}
# Pseudo-code PLS-DA
# 1. Encoder Y en matrice binaire (ALL=[1,0], AML=[0,1])
# 2. Trouver composantes t_h qui maximisent Cov(X, Y)
# 3. Classification sur les composantes t_h
```

**Avantages :**
- ‚úÖ Optimisation directe pour la discrimination
- ‚úÖ Souvent plus performante que PCR en classification
- ‚úÖ Moins de composantes n√©cessaires

**Inconv√©nients :**
- ‚ùå Plus complexe √† interpr√©ter que PCR
- ‚ùå Risque de sur-ajustement si mal r√©gularis√©e

#### ACP + LDA (Analyse en Composantes Principales + Analyse Discriminante Lin√©aire)

**Principe :**
- **√âtape 1** : ACP non supervis√©e pour r√©duction de dimension
- **√âtape 2** : LDA sur les composantes principales pour classification optimale
- Combinaison de deux m√©thodes classiques bien √©tablies

```{r acp_lda_implementation}
# Impl√©mentation ACP + LDA
print("Impl√©mentation ACP + LDA")

# Utiliser les composantes principales d√©j√† calcul√©es
library(MASS)

# LDA sur les composantes principales (utilisation de 85% variance)
lda_model <- lda(Y ~ ., data = train_data_classical)

# Pr√©dictions LDA
lda_predictions <- predict(lda_model, test_data_classical)
pred_class_lda <- lda_predictions$class
accuracy_lda <- mean(pred_class_lda == y_test)

# Matrice de confusion
confusion_lda <- table(Predicted = pred_class_lda, Actual = y_test)

# Probabilit√©s post√©rieures LDA
lda_probabilities <- lda_predictions$posterior[, "AML"]

# R√©sultats ACP + LDA
lda_results <- data.frame(
  Metrique = c("Accuracy ACP + LDA", "Exemple probabilit√©s"),
  Valeur = c(round(accuracy_lda, 3), paste(round(head(lda_probabilities), 3), collapse=", "))
)
print(lda_results)

print("Matrice de confusion ACP + LDA:")
print(confusion_lda)
```

**Avantages de ACP + LDA :**
- ‚úÖ M√©thode classique bien √©tablie et comprise
- ‚úÖ Optimisation sp√©cifique pour la s√©parabilit√© des classes
- ‚úÖ Interpr√©tation g√©om√©trique claire (axes discriminants)
- ‚úÖ Robuste et stable

**Inconv√©nients :**
- ‚ùå Hypoth√®se de normalit√© multivari√©e
- ‚ùå Moins flexible que la r√©gression logistique
- ‚ùå Peut √™tre sensible aux donn√©es aberrantes

#### Comparaison des quatre m√©thodes

```{r comparison_four_methods}
# R√©capitulatif des quatre approches
methods_comparison <- data.frame(
  Methode = c("PCR Classique", "PCR Adapt√©e", "ACP + LDA", "PLS-DA (th√©orique)"),
  Accuracy = c(accuracy_numeric, accuracy_categorical, accuracy_lda, NA),
  Type = c("Non supervis√©e", "Non supervis√©e", "Hybride", "Supervis√©e"),
  Validite_Statistique = c("Faible", "Forte", "Forte", "Forte"),
  Interpretabilite = c("Difficile", "Bonne", "Tr√®s bonne", "Moyenne")
)

print("Comparaison des quatre m√©thodes :")
print(methods_comparison)

# Graphique comparatif des accuracies
accuracies_plot <- c(accuracy_numeric, accuracy_categorical, accuracy_lda)
method_names <- c("PCR\nClassique", "PCR\nAdapt√©e", "ACP +\nLDA")

barplot(accuracies_plot,
        names.arg = method_names,
        col = c("lightcoral", "lightblue", "lightgreen"),
        ylim = c(0, 1),
        main = "Comparaison des performances\n(Accuracy sur donn√©es test)",
        ylab = "Accuracy")
text(1:3, accuracies_plot + 0.05,
     labels = round(accuracies_plot, 3),
     pos = 3)
```

## 5. D√©cision pour la Question 4 du projet

### 5.1 Synth√®se de notre analyse pr√©liminaire

Apr√®s cette investigation approfondie, **nos conclusions sont claires** :

#### ‚úÖ Approche retenue : PCR adapt√©e (ACP + r√©gression logistique)

**Justifications pour la Question 4 :**

1. **Validit√© statistique** : Respecte la nature cat√©gorielle de notre variable Y
2. **Performance** : Accuracy de `r round(accuracy_pcr1, 3)` sur nos donn√©es test
3. **Robustesse** : M√©thode reconnue acad√©miquement et utilis√©e en pratique
4. **Comparabilit√©** : Permettra une comparaison √©quitable avec le Lasso dans la Question 4

#### ‚ùå Approche √©cart√©e : PCR avec transformation num√©rique 

**Raisons du rejet :**
- Accuracy similaire (`r round(accuracy_numeric, 3)`) mais **m√©thodologiquement incorrecte**
- Violation des hypoth√®ses de la r√©gression lin√©aire
- Pr√©dictions sans interpr√©tation probabiliste coh√©rente

### 5.2 Impl√©mentation finale pour la Question 4

**Notre choix technique pour la suite du projet :**

```{r final_choice_summary}
final_choice <- data.frame(
  Element = c("M√©thode PCR retenue", "Crit√®re de s√©lection", "Nombre optimal composantes", "Performance de r√©f√©rence"),
  Valeur = c("ACP + R√©gression Logistique", "Validation crois√©e", optimal_ncomp, round(accuracy_pcr1, 3))
)

# Choix final avec formatage appropri√©
if (use_kableExtra) {
  kable(final_choice, 
        caption = "**Tableau 9**: Choix final pour la Question 4 du projet",
        col.names = c("√âl√©ment", "Valeur")) %>%
    kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE) %>%
    column_spec(2, bold = TRUE, color = "#155724", background = "#d4edda")
} else {
  format_table(final_choice, 
               caption = "**Tableau 9**: Choix final pour la Question 4 du projet",
               col_names = c("√âl√©ment", "Valeur"))
}

cat("\nCette approche sera utilis√©e pour :\n")
cat("- R√©aliser la PCR de la Question 4\n")
cat("- Comparer avec les r√©sultats du Lasso\n") 
cat("- Discuter les diff√©rences d'approche\n")
cat("- Analyser ce qu'on perd en passant aux composantes principales\n")
```

### 5.3 Pr√©paration de la comparaison PCR vs Lasso

**Points de comparaison pr√©vus :**

1. **Performance pr√©dictive** : Accuracy, sensibilit√©, sp√©cificit√©
2. **Complexit√© du mod√®le** : Nombre de variables/composantes utilis√©es  
3. **Interpr√©tabilit√©** : Variables s√©lectionn√©es vs composantes principales
4. **Stabilit√©** : Robustesse face aux variations des donn√©es

### 5.4 R√©ponse √† la question guid√©e

**"Que perd-on en passant des variables initiales aux composantes principales ?"**

Notre analyse nous permettra de quantifier :
- **Perte d'interpr√©tabilit√© directe** : Les PC sont des combinaisons lin√©aires abstraites
- **Perte de parcimonie** : Toutes les variables contribuent vs s√©lection Lasso
- **Gain en stabilit√© num√©rique** : R√©duction p >> n ‚Üí quelques composantes
- **Gain en performance** : √Ä √©valuer empiriquement vs Lasso

### Conclusion de cette √©tude pr√©liminaire

::: {.callout-important}
## üéØ D√©cision m√©thodologique pour la Question 4

Cette analyse comparative nous a permis de **faire un choix m√©thodologique √©clair√©**. Nous proc√©derons maintenant √† l'impl√©mentation de la **Question 4 avec la PCR adapt√©e**, confiants dans la validit√© statistique de notre approche et pr√™ts √† la comparer rigoureusement avec le Lasso.

**Approche retenue** : PCR adapt√©e (ACP + r√©gression logistique) avec s√©lection du nombre de composantes par validation crois√©e.
:::

Cette analyse comparative nous a permis de **faire un choix m√©thodologique √©clair√©**. Nous proc√©derons maintenant √† l'impl√©mentation de la **Question 4 avec la PCR adapt√©e**, confiants dans la validit√© statistique de notre approche et pr√™ts √† la comparer rigoureusement avec le Lasso.
|-------------------|-------------------|---------------|
| **Performance maximale** | PLS-DA > ACP+LDA > PCR adapt√©e | Optimisation supervis√©e |
| **Simplicit√© d'impl√©mentation** | PCR adapt√©e | Packages R standards |
| **Interpr√©tabilit√©** | ACP+LDA > PCR adapt√©e | Axes discriminants clairement d√©finis |
| **Robustesse** | PCR adapt√©e | Moins d'hypoth√®ses restrictives |
| **Publication scientifique** | ACP+LDA ou PLS-DA | M√©thodes reconnues acad√©miquement |

#### Consid√©rations pour l'extension multiclasse

Notre exemple traite d'une classification binaire (ALL vs AML), mais les principes s'√©tendent naturellement :

- **PCR adapt√©e** : R√©gression logistique multinomiale
- **ACP + LDA** : LDA multiclasse directement
- **PLS-DA** : PLS-DA multiclasse

#### Validation et √©valuation

**M√©triques recommand√©es :**
- Accuracy globale (utilis√©e ici)
- Sensibilit√© et sp√©cificit√© par classe
- Courbes ROC et AUC (pour l'approche probabiliste)
- Validation crois√©e k-fold pour robustesse

**Diagnostic du mod√®le :**
- Analyse des r√©sidus (pour r√©gression logistique)
- Test de normalit√© multivari√©e (pour LDA)
- Analyse de la s√©parabilit√© des classes

#### Conclusion g√©n√©rale

Cette comparaison d√©montre clairement que :

1. **La PCR classique avec transformation num√©rique est m√©thodologiquement incorrecte** pour une variable cible cat√©gorielle
2. **La PCR adapt√©e (ACP + r√©gression logistique) constitue une approche valide et robuste** pour la classification en haute dimension
3. **Les m√©thodes sp√©cialis√©es (ACP+LDA, PLS-DA) peuvent offrir de meilleures performances** selon le contexte
4. **Le choix final d√©pend du compromis entre performance, interpr√©tabilit√© et complexit√© d'impl√©mentation**

Dans le contexte de donn√©es de haute dimension (p >> n), toutes les m√©thodes appropri√©es (PCR adapt√©e, ACP+LDA, PLS-DA) offrent une solution efficace au probl√®me de dimensionnalit√© tout en respectant la nature cat√©gorielle de la variable √† expliquer.