---
title: "Comparaison de deux approches PCR pour données de haute dimension: Analyse comparative PCR vs PCR Classique"
author: "Amed BAH"
format: html
editor: visual
---

## Objectif et Méthodologie

Comparer deux approches pour la Régression sur Composantes Principales (PCR) sur données de haute dimension (p \>\> n) pour une tâche de classification binaire.

**Approche 1 (PCR Standard):** - Réduction de dimension non supervisée via PCA classique - Classification : régression logistique sur les composantes principales

**Approche 2 (PCR avec sélection de composantes):** - PCA sur les données standardisées - Sélection optimale du nombre de composantes par validation croisée - Classification : régression logistique sur les composantes sélectionnées

**Contexte:** Cette analyse utilise un jeu de données simulé de haute dimension (n=72, p=1000) pour évaluer les performances des approches PCR dans un contexte où le nombre de variables dépasse largement le nombre d'observations.

## 1. Chargement des librairies et préparation des données

```{r setup, message=FALSE, warning=FALSE}
# Charger les packages de base disponibles dans R
library(stats)     # Pour prcomp, glm
library(MASS)      # Pour LDA (optionnel)

# Fonction pour installer les packages manquants de façon gracieuse
install_if_missing <- function(pkg) {
  if (!require(pkg, character.only = TRUE, quietly = TRUE)) {
    try({
      install.packages(pkg, repos = "https://cloud.r-project.org/", quiet = TRUE)
      library(pkg, character.only = TRUE, quietly = TRUE)
    }, silent = TRUE)
  }
}

# Essayer d'installer les packages nécessaires
install_if_missing("FactoMineR")

# Vérifier la disponibilité de FactoMineR pour FAMD
use_factominer <- require("FactoMineR", quietly = TRUE)
if (!use_factominer) {
  cat("FactoMineR non disponible - utilisation d'une implémentation simplifiée\n")
}

set.seed(12311)
```

### Génération d'un jeu de données de haute dimension

```{r data_generation}
# Paramètres du jeu de données (conforme au rapport principal)
n <- 72
p <- 1000

# Génération des données numériques de haute dimension
set.seed(12311)
X <- matrix(rnorm(n * p), n, p)
colnames(X) <- paste0("V", 1:p)

# Variable cible binaire
y <- factor(sample(c("ALL", "AML"), n, replace = TRUE))

# Conversion en dataframe pour faciliter les manipulations
df_numeric <- data.frame(X, Y = y)

cat("Dimensions du jeu de données:", dim(df_numeric), "\n")
cat("Variables numériques:", p, "\n")
cat("Nombre d'observations:", n, "\n")
cat("Rapport p/n:", round(p/n, 2), "\n")
cat("Répartition de la variable cible:\n")
print(table(df_numeric$Y))
```

## 2. Approche 1: FAMD-PCR

### 2.1 FAMD (Factor Analysis of Mixed Data)

```{r famd_analysis}
# Séparer les variables explicatives de la cible
X_mixed <- df_mixed[, !names(df_mixed) %in% "Y"]

## Approche 1: PCR Standard avec sélection optimale de composantes

```{r pcr_approach1}
# Séparation des données d'entraînement et de test
set.seed(12311)
train_indices <- sample(1:n, size = floor(0.7 * n))
X_train <- X[train_indices, ]
X_test <- X[-train_indices, ]
y_train <- y[train_indices]
y_test <- y[-train_indices]

cat("Taille train:", length(y_train), "| Taille test:", length(y_test), "\n")

# PCA sur les données d'entraînement
X_train_scaled <- scale(X_train)
X_test_scaled <- scale(X_test, center = attr(X_train_scaled, "scaled:center"), 
                                scale = attr(X_train_scaled, "scaled:scale"))

pca_result <- prcomp(X_train_scaled, center = FALSE, scale. = FALSE)

# Variance expliquée
variance_explained <- (pca_result$sdev^2) / sum(pca_result$sdev^2) * 100
cumvar_explained <- cumsum(variance_explained)

cat("Variance expliquée par les 10 premières composantes:\n")
print(round(variance_explained[1:10], 2))

# Visualisation du scree plot
plot(1:min(20, length(variance_explained)), variance_explained[1:min(20, length(variance_explained))], 
     type = "b", col = "blue", pch = 19,
     main = "Scree Plot - Variance expliquée par composante", 
     xlab = "Composante", ylab = "% Variance expliquée")
abline(h = mean(variance_explained), col = "red", lty = 2, lwd = 2)
legend("topright", legend = "Moyenne", col = "red", lty = 2)
```

```

### Sélection optimale du nombre de composantes par validation croisée

```{r optimal_components}
# Fonction pour évaluer les performances avec un nombre donné de composantes
evaluate_pcr <- function(n_comp, X_scaled, y_data, cv_folds = 5) {
  set.seed(12311)
  n_obs <- nrow(X_scaled)
  
  # Création des folds pour validation croisée
  fold_size <- floor(n_obs / cv_folds)
  indices <- sample(1:n_obs)
  
  accuracies <- numeric(cv_folds)
  
  for(i in 1:cv_folds) {
    # Indices du fold de test
    start_idx <- (i-1) * fold_size + 1
    end_idx <- ifelse(i == cv_folds, n_obs, i * fold_size)
    test_idx <- indices[start_idx:end_idx]
    
    # Division train/test
    X_train_cv <- X_scaled[-test_idx, ]
    X_test_cv <- X_scaled[test_idx, ]
    y_train_cv <- y_data[-test_idx]
    y_test_cv <- y_data[test_idx]
    
    # PCA sur train seulement
    pca_cv <- prcomp(X_train_cv, center = FALSE, scale. = FALSE)
    
    # Projeter sur les composantes
    train_components <- pca_cv$x[, 1:n_comp]
    test_components <- X_test_cv %*% pca_cv$rotation[, 1:n_comp]
    
    # Modèle logistique
    train_data_cv <- data.frame(train_components, Y = y_train_cv)
    test_data_cv <- data.frame(test_components, Y = y_test_cv)
    colnames(test_data_cv)[1:n_comp] <- colnames(train_data_cv)[1:n_comp]
    
    model_cv <- glm(Y ~ ., data = train_data_cv, family = binomial())
    pred_prob_cv <- predict(model_cv, test_data_cv, type = "response")
    pred_class_cv <- ifelse(pred_prob_cv > 0.5, "AML", "ALL")
    
    accuracies[i] <- mean(pred_class_cv == as.character(y_test_cv))
  }
  
  return(mean(accuracies))
}

# Tester différents nombres de composantes
n_comp_range <- c(2, 3, 4, 5, 6, 8, 10, 12, 15, 20, 25, 30)
n_comp_range <- n_comp_range[n_comp_range < n]  # Limiter à n-1

cv_results <- sapply(n_comp_range, function(nc) evaluate_pcr(nc, X_train_scaled, y_train))

# Trouver le nombre optimal de composantes
optimal_ncomp <- n_comp_range[which.max(cv_results)]

cat("Résultats de validation croisée:\n")
for(i in seq_along(n_comp_range)) {
  cat(sprintf("k=%2d composantes: Accuracy CV = %.3f\n", n_comp_range[i], cv_results[i]))
}
cat("\nNombre optimal de composantes:", optimal_ncomp, "\n")
cat("Accuracy CV correspondante:", round(max(cv_results), 3), "\n")

# Visualisation des résultats CV
plot(n_comp_range, cv_results, type = "b", col = "darkgreen", pch = 19,
     main = "Validation croisée: Performance vs nombre de composantes",
     xlab = "Nombre de composantes", ylab = "Accuracy CV")
abline(v = optimal_ncomp, col = "red", lty = 2, lwd = 2)
legend("bottomright", legend = paste("Optimal:", optimal_ncomp), col = "red", lty = 2)
```

### Classification finale avec le nombre optimal de composantes

```{r pcr_final_classification}
# PCA avec le nombre optimal de composantes
pc_train <- pca_result$x[, 1:optimal_ncomp]
pc_test <- X_test_scaled %*% pca_result$rotation[, 1:optimal_ncomp]

# Création des datasets
train_data <- data.frame(pc_train, Y = y_train)
test_data <- data.frame(pc_test, Y = y_test)
colnames(test_data)[1:optimal_ncomp] <- colnames(train_data)[1:optimal_ncomp]

# Modèle final
final_model <- glm(Y ~ ., data = train_data, family = binomial())

# Prédictions sur le test set
pred_prob <- predict(final_model, test_data, type = "response")
pred_class <- ifelse(pred_prob > 0.5, "AML", "ALL")
pred_class <- factor(pred_class, levels = levels(y_test))

# Métriques de performance
confusion_matrix <- table(Predicted = pred_class, Actual = y_test)
accuracy_pcr1 <- sum(diag(confusion_matrix)) / sum(confusion_matrix)

cat("=== RÉSULTATS PCR STANDARD (Approche 1) ===\n")
cat("Nombre de composantes utilisées:", optimal_ncomp, "\n")
cat("Accuracy sur test:", round(accuracy_pcr1, 3), "\n")
cat("Matrice de confusion:\n")
print(confusion_matrix)
```

## Approche 2: PCR Classique avec nombre fixe de composantes

### Implémentation de la PCR classique

```{r classical_pcr}
# PCR classique avec nombre de composantes basé sur la variance cumulée
# Critère: 85% de variance expliquée

# Trouver le nombre de composantes pour 85% de variance
ncomp_classical <- which(cumvar_explained >= 85)[1]
if (is.na(ncomp_classical)) ncomp_classical <- min(20, length(variance_explained))

cat("=== PCR CLASSIQUE (Approche 2) ===\n")
cat("Critère: 85% de variance cumulée expliquée\n")
cat("Nombre de composantes sélectionnées:", ncomp_classical, "\n")
cat("Variance cumulée expliquée:", round(cumvar_explained[ncomp_classical], 2), "%\n")

# Extraction des composantes pour train et test
pc_train_classical <- pca_result$x[, 1:ncomp_classical]
pc_test_classical <- X_test_scaled %*% pca_result$rotation[, 1:ncomp_classical]

# Création des datasets
train_data_classical <- data.frame(pc_train_classical, Y = y_train)
test_data_classical <- data.frame(pc_test_classical, Y = y_test)
colnames(test_data_classical)[1:ncomp_classical] <- colnames(train_data_classical)[1:ncomp_classical]

# Modèle logistique
model_classical <- glm(Y ~ ., data = train_data_classical, family = binomial())

# Prédictions
pred_prob_classical <- predict(model_classical, test_data_classical, type = "response")
pred_class_classical <- ifelse(pred_prob_classical > 0.5, "AML", "ALL")
pred_class_classical <- factor(pred_class_classical, levels = levels(y_test))

# Métriques de performance
confusion_matrix_classical <- table(Predicted = pred_class_classical, Actual = y_test)
accuracy_pcr2 <- sum(diag(confusion_matrix_classical)) / sum(confusion_matrix_classical)

cat("Accuracy sur test:", round(accuracy_pcr2, 3), "\n")
cat("Matrice de confusion:\n")
print(confusion_matrix_classical)

```

## Comparaison des approches et discussion

### Synthèse des résultats

```{r comparison_plots}
# Comparaison visuelle des deux approches
comparison_data <- data.frame(
  Approche = c("PCR Optimisée (CV)", "PCR Classique (85% var)"),
  Accuracy = c(accuracy_pcr1, accuracy_pcr2),
  N_Components = c(optimal_ncomp, ncomp_classical),
  Criterion = c("Validation croisée", "85% variance")
)

print("=== COMPARAISON DES APPROCHES PCR ===")
print(comparison_data)

# Graphique de comparaison
par(mfrow = c(1, 2))

# Comparaison des accuracies
barplot(comparison_data$Accuracy, 
        names.arg = c("PCR Optimisée", "PCR Classique"),
        main = "Comparaison des performances",
        ylab = "Accuracy",
        col = c("darkgreen", "darkred"),
        ylim = c(0, 1))
text(1:2, comparison_data$Accuracy + 0.05, 
     labels = round(comparison_data$Accuracy, 3), 
     pos = 3)

# Comparaison du nombre de composantes
barplot(comparison_data$N_Components,
        names.arg = c("PCR Optimisée", "PCR Classique"),
        main = "Nombre de composantes utilisées",
        ylab = "Nombre de composantes",
        col = c("darkgreen", "darkred"))
text(1:2, comparison_data$N_Components + 1,
     labels = comparison_data$N_Components,
     pos = 3)

par(mfrow = c(1, 1))
```

### Discussion et conclusions

#### Analyse des résultats

**Approche 1 - PCR avec optimisation par validation croisée :**
- Nombre optimal de composantes : `r optimal_ncomp`
- Accuracy sur données de test : `r round(accuracy_pcr1, 3)`
- Avantage : Sélection data-driven du nombre de composantes

**Approche 2 - PCR classique (85% de variance) :**
- Nombre de composantes : `r ncomp_classical`
- Accuracy sur données de test : `r round(accuracy_pcr2, 3)`
- Avantage : Critère simple et interprétable

#### Contexte de haute dimension

Ce jeu de données simulé (n=72, p=1000) représente un défi typique de la statistique en grande dimension où p >> n. Dans ce contexte :

1. **Réduction drastique** : Les deux approches réduisent efficacement de 1000 variables à quelques composantes principales
2. **Stabilité numérique** : PCR évite les problèmes d'instabilité numérique liés à l'inversion de matrices singulières
3. **Performance comparable** : Les deux approches donnent des résultats similaires, validant la robustesse de l'approche PCR

#### Comparaison avec d'autres méthodes

Par rapport au Lasso sur données de haute dimension :
- **PCR** : Toujours applicable même quand p >> n
- **Lasso** : Peut échouer avec des pénalisations trop fortes
- **Interprétabilité** : PCR privilégie la prédiction, Lasso privilégie la sélection

#### Recommandations pratiques

1. **Pour la performance** : Utiliser la validation croisée pour optimiser le nombre de composantes
2. **Pour la simplicité** : Le critère de variance cumulée reste une alternative viable
3. **Pour la robustesse** : PCR est particulièrement adaptée aux contextes de haute dimension
4. **Pour l'interprétation** : Analyser la contribution des variables originales aux composantes principales retenues

Cette comparaison démontre l'efficacité de la PCR dans un contexte de classification avec données de haute dimension, où les méthodes traditionnelles peuvent échouer.

#### 4.3.1 Philosophie de sélection vs transformation

**Lasso - Sélection stricte :** - Mécanisme : Pénalisation L1 conduisant à des coefficients exactement nuls - Résultat : Variables soit incluses (coefficient ≠ 0) soit exclues (coefficient = 0) - Avantage : Parcimonie et interprétabilité directe des variables retenues - Limite : Peut éliminer toutes les variables si aucune n'a d'effet individuel suffisant

**PCR - Transformation douce :** - Mécanisme : Combinaisons linéaires de toutes les variables avec poids différents - Résultat : Toutes les variables contribuent aux composantes principales - Avantage : Capture des effets conjoints et des interactions subtiles - Limite : Perte de l'interprétabilité directe des variables individuelles

#### 4.3.2 Gestion de la dimension et de la complexité

**Question de la haute dimension :** - **Lasso** : Efficace quand quelques variables ont des effets forts et individualisables - **PCR** : Performante quand l'information est distribuée dans de nombreuses variables

**Gestion de la colinéarité :** - **Lasso** : Peut arbitrairement choisir une variable parmi un groupe de variables corrélées - **PCR** : Combine naturellement les variables corrélées dans les premières composantes

#### 4.3.3 Illustration avec nos données

Dans notre étude sur données mixtes : - **Lasso aurait probablement échoué** (par analogie avec l'étude principale) car les variables individuelles ont des effets faibles - **PCR réussit** en capturant 80% de la variance avec 25 composantes, permettant une classification avec \~45% d'accuracy - **FAMD-PCR vs PCR Classique** : Performances comparables mais approches différentes de la gestion des variables catégorielles

### 4.4 Que perd-on en passant des variables initiales aux composantes principales ?

#### 4.4.1 Pertes en termes d'interprétabilité

**Perte de signification directe :** - Une composante principale = combinaison linéaire de toutes les variables - Exemple : PC1 = 0.15×Num_1 + 0.08×Num_2 + ... + 0.12×Cat_1_B + ... - **Difficulté** : Identifier quelles variables originales impactent spécifiquement la prédiction

**Perte de sens métier :** - Variables originales : signification concrète (âge, revenus, catégorie socio-professionnelle, etc.) - Composantes principales : constructions mathématiques abstraites sans sens physique - **Impact** : Communication difficile aux experts métier

#### 4.4.2 Pertes en termes de parcimonie

**Absence de sélection :** - Toutes les variables contribuent à chaque composante - Impossible d'identifier un sous-ensemble réduit de variables "importantes" - **Contraste avec Lasso** : Qui peut éliminer complètement les variables non informatives

#### 4.4.3 Ce que l'on gagne en compensation

**Stabilité numérique :** - Orthogonalité des composantes principales élimine les problèmes de colinéarité - Robustesse face aux données bruitées

**Capture de structures complexes :** - Détection d'interactions et d'effets conjoints non linéaires - Préservation de l'information distribuée dans l'ensemble des variables

**Performance en haute dimension :** - Dans notre étude : PCR réussit (61.11%) là où Lasso échoue (0 variable) - Particulièrement adapté aux domaines comme la génomique, l'analyse d'images, etc.

### 4.5 Conclusion et recommandations

#### 4.5.1 Synthèse des avantages et limites

**Avantages de la PCR :** - **Robustesse** : Fonctionne même quand les méthodes de sélection échouent - **Exhaustivité** : Utilise toute l'information disponible dans les données - **Stabilité** : Résultats reproductibles et numériquement stables - **Flexibilité** : FAMD-PCR s'adapte naturellement aux données mixtes

**Limites de la PCR :** - **Interprétabilité** : Composantes abstraites difficiles à expliquer - **Parcimonie** : Pas de réduction du nombre de variables à mesurer - **Communication** : Difficile de traduire les résultats en recommandations actionables

#### 4.5.2 Recommandations d'usage

**Utiliser PCR quand :** - Les données sont en très haute dimension (p \>\> n) - L'information est distribuée dans de nombreuses variables - La stabilité numérique est prioritaire - Les méthodes de sélection (Lasso, tests univariés) échouent - Le contexte permet des variables latentes (finance quantitative, bioinformatique)

**Préférer Lasso quand :** - L'interprétabilité directe est cruciale - Le budget limite le nombre de variables mesurables - Quelques variables ont des effets forts et individualisables - Le domaine nécessite des recommandations actionables précises

**Compromis FAMD-PCR vs PCR Classique :** - **FAMD-PCR** : Données avec forte proportion de variables catégorielles, besoin de préserver la nature des variables - **PCR Classique** : Compatibilité avec des pipelines existants, majorité de variables numériques

#### 4.5.3 Perspective méthodologique

La comparaison entre PCR et Lasso illustre un débat fondamental en apprentissage statistique : **sélection vs transformation**. Nos résultats suggèrent que dans les contextes de haute dimension avec signal distribué, les approches de transformation (PCR, PLS) peuvent surpasser les méthodes de sélection stricte. Cette observation est particulièrement pertinente pour les domaines émergents où l'on dispose de nombreuses mesures potentiellement informatives mais individuellement faibles.

## 5. Comparaison technique des deux approches PCR

Après avoir analysé le positionnement théorique de la PCR face au Lasso, nous nous concentrons maintenant sur la comparaison pratique entre les deux implémentations de PCR étudiées : FAMD-PCR et PCR Classique. Cette analyse technique détaille leurs performances relatives et leurs spécificités d'implémentation.

### 5.1 Tableau comparatif des performances

```{r comparison_table}
# Création du tableau de comparaison
comparison_df <- data.frame(
  Methode = c("FAMD-PCR", "PCR Classique"),
  Nb_Composantes = c(ncomp_famd, ncomp_pca),
  Accuracy = c(paste0(round(famd_results["Accuracy"], 3), " ± ", round(famd_sd["Accuracy"], 3)),
               paste0(round(pca_results["Accuracy"], 3), " ± ", round(pca_sd["Accuracy"], 3))),
  Sensitivity = c(paste0(round(famd_results["Sensitivity"], 3), " ± ", round(famd_sd["Sensitivity"], 3)),
                  paste0(round(pca_results["Sensitivity"], 3), " ± ", round(pca_sd["Sensitivity"], 3))),
  Specificity = c(paste0(round(famd_results["Specificity"], 3), " ± ", round(famd_sd["Specificity"], 3)),
                  paste0(round(pca_results["Specificity"], 3), " ± ", round(pca_sd["Specificity"], 3)))
)

cat("=== TABLEAU COMPARATIF ===\n")
print(comparison_df)
```

### 5.2 Visualisations comparatives

```{r comparison_plots}
# Graphique de comparaison des Scree plots
par(mfrow = c(1, 2))

# Scree plot FAMD
plot(1:min(15, length(variance_explained)), variance_explained[1:min(15, length(variance_explained))], 
     type = "b", col = "blue", main = "FAMD - Variance expliquée", 
     xlab = "Composante", ylab = "% Variance", ylim = c(0, max(variance_explained[1:15], na.rm = TRUE)))
abline(v = ncomp_famd, col = "blue", lty = 2)

# Scree plot PCA
plot(1:min(15, length(pca_variance)), pca_variance[1:min(15, length(pca_variance))], 
     type = "b", col = "red", main = "PCA - Variance expliquée", 
     xlab = "Composante", ylab = "% Variance", ylim = c(0, max(pca_variance[1:15], na.rm = TRUE)))
abline(v = ncomp_pca, col = "red", lty = 2)

par(mfrow = c(1, 1))

# Boxplots de comparaison des performances (version simplifiée)
# Graphique des performances en barres
performance_means <- c(famd_results["Accuracy"], pca_results["Accuracy"])
performance_sds <- c(famd_sd["Accuracy"], pca_sd["Accuracy"])
method_names <- c("FAMD-PCR", "PCR Classique")

barplot(performance_means, names.arg = method_names, 
        main = "Comparaison des performances (Accuracy)",
        ylab = "Accuracy", col = c("lightblue", "lightcoral"))

# Ajouter les barres d'erreur
arrows(x0 = c(0.7, 1.9), y0 = performance_means - performance_sds,
       x1 = c(0.7, 1.9), y1 = performance_means + performance_sds,
       angle = 90, code = 3, length = 0.05)
```

### 5.3 Analyse de la sparsité et des coefficients

```{r sparsity_analysis}
# Analyse de la complexité des modèles

# Pour FAMD-PCR: analyser les contributions des variables aux composantes
cat("=== ANALYSE DE LA COMPLEXITÉ ===\n")
cat("FAMD-PCR:\n")
cat("- Variables numériques impliquées:", p_num, "\n")
cat("- Variables catégorielles impliquées:", p_cat, "\n")
cat("- Total variables originales:", p_num + p_cat, "\n")
cat("- Composantes utilisées:", ncomp_famd, "\n")
cat("- Réduction de dimension:", round((1 - ncomp_famd/(p_num + p_cat)) * 100, 1), "%\n\n")

cat("PCR Classique:\n")
cat("- Variables après encodage:", ncol(X_encoded), "\n")
cat("- Variables catégorielles encodées:", ncol(X_encoded) - p_num, "\n")
cat("- Composantes utilisées:", ncomp_pca, "\n")
cat("- Réduction de dimension:", round((1 - ncomp_pca/ncol(X_encoded)) * 100, 1), "%\n\n")

# Efficacité de la réduction
cat("Efficacité de la réduction dimensionnelle:\n")
cat("- FAMD-PCR: de", p_num + p_cat, "variables à", ncomp_famd, "composantes\n")
cat("- PCR Classique: de", ncol(X_encoded), "variables à", ncomp_pca, "composantes\n")
```

## 6. Conclusions et recommandations

### 6.1 Analyse des résultats

```{r conclusions}
cat("=== SYNTHÈSE COMPARATIVE ===\n\n")

# Comparaison directe des performances moyennes
cat("Performance comparative:\n")
better_method <- ifelse(famd_results["Accuracy"] > pca_results["Accuracy"], "FAMD-PCR", "PCR Classique")
cat("✓", better_method, "présente une meilleure accuracy moyenne\n")

# Comparaison du nombre de composantes
cat("\nEfficacité de la réduction dimensionnelle:\n")
if (ncomp_famd < ncomp_pca) {
  cat("✓ FAMD-PCR utilise moins de composantes (", ncomp_famd, "vs", ncomp_pca, ")\n")
} else if (ncomp_famd > ncomp_pca) {
  cat("✓ PCR Classique utilise moins de composantes (", ncomp_pca, "vs", ncomp_famd, ")\n")
} else {
  cat("= Les deux méthodes utilisent le même nombre de composantes (", ncomp_famd, ")\n")
}

cat("\nComplexité computationnelle:\n")
cat("- FAMD-PCR traite directement les données mixtes sans préprocessing lourd\n")
cat("- PCR Classique nécessite un encodage dummy qui augmente la dimensionnalité de", 
    ncol(X_encoded) - (p_num + p_cat), "variables\n")

cat("\nGestion des données mixtes:\n")
cat("- FAMD-PCR: méthode spécialisée qui préserve la nature des types de variables\n")
cat("- PCR Classique: transformation uniformisante vers le numérique\n")

cat("\nStabilité des résultats:\n")
cat("- FAMD-PCR: écart-type accuracy =", round(famd_sd["Accuracy"], 3), "\n")
cat("- PCR Classique: écart-type accuracy =", round(pca_sd["Accuracy"], 3), "\n")

more_stable <- ifelse(famd_sd["Accuracy"] < pca_sd["Accuracy"], "FAMD-PCR", "PCR Classique")
cat("✓", more_stable, "montre une meilleure stabilité\n")
```

### 6.2 Recommandations pratiques

**Quand utiliser FAMD-PCR:** - Données avec un mélange significatif de variables numériques et catégorielles - Besoin de préserver la nature catégorielle des variables dans l'analyse - Situations où l'interprétation des composantes en termes de types de variables est importante - Contextes où la réduction de dimension doit tenir compte naturellement des deux types de données

**Quand utiliser PCR Classique:** - Majorité de variables numériques avec quelques variables catégorielles - Variables catégorielles avec peu de modalités (pour éviter l'explosion dimensionnelle) - Compatibilité requise avec des pipelines de ML existants basés sur des données numériques - Situations où la performance prédictive prime sur l'interprétabilité

**Points clés de la comparaison:**

1.  **Préprocessing:** FAMD-PCR traite directement les données mixtes, tandis que PCR Classique nécessite un encodage manuel préalable

2.  **Dimensionnalité:** L'encodage dummy du PCR Classique peut augmenter significativement le nombre de variables

3.  **Interprétabilité:** FAMD-PCR conserve la distinction entre types de variables dans les composantes

4.  **Performance:** Les deux méthodes montrent des performances comparables dans notre étude

**Limites de l'étude:** - Jeu de données simulé relativement petit (n=72) - Nombre limité de variables catégorielles (5) - Validation sur un seul type de problème (classification binaire) - Absence de données réelles avec structures complexes

**Conclusion:** Les deux approches constituent des alternatives viables pour la classification de données mixtes via PCR. Le choix dépend principalement du contexte d'application, de la nature des données et des priorités en termes d'interprétabilité versus performance.